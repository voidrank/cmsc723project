[![](https://globalvoices.org/wp-
content/uploads/2017/09/whatsapp-2503235_1280-800x450.jpg)](https://pixabay.com/en/whatsapp-
communication-2503235/)

Image via Pixabay. From Public Domain.

With the number of [social media users in
India](http://www.exchange4media.com/digital/active-social-media-users-in-
india-grow-by-15--from-2015-to-become-136-million-yral-report-2016_67225.html)
rapidly rising, the dissemination of fake news has become a widespread
phenomenon in recent years.

So-called “information overload” has made it difficult to separate the wheat
from the chaff, and in some cases, misinformation spread via social media
appears to have precipitated real-life violence, sometimes with [fatal
consequences](https://thewire.in/138667/whatsapp-message-turns-tribals-
violent-leaves-seven-dead/).

In one recent incident, Twitter users in India expressed their anger when a
ruling party member shared an image taken out of context, in what seemed like
an effort to stoke social tensions during a riot in the Indian state of West
Bengal. [Several such images](http://www.dailyo.in/variety/bjp-nupur-sharma-
bengal-violence-fake-image-2002-gujarat-riots/story/1/18263.html) were
circulated through social media to skew public opinion in this period. In
2015, a possibly fake image circulated via WhatsApp and was later linked to
the subsequent [lynching](http://www.huffingtonpost.in/2015/09/30/beef-
killing-up_n_8219828.html) of a Muslim man in India, on the suspicion that he
had slaughtered a cow.

In India, reporting misinformation to police can be a first step towards
prosecuting its sender under [Indian laws](http://www.firstpost.com/tech/news-
analysis/the-fake-news-problem-in-india-can-get-out-of-hand-if-not-controlled-
in-due-time-experts-tell-us-why-3697929.html) like Section 67 of the IT act,
if the information is perceived as likely to be “harmful to young minds”, or
section 468 of IPC if the news is considered “detrimental” to someone's
reputation. But policies like these are hard to implement effectively,
routinely running afoul of protections for free expression.

Online civil society is also increasingly proactive, with the emergence of
several [hoax-slaying initiatives](http://www.bbc.com/news/world-asia-
india-40657074) run by do-gooders from different spheres of life who try to
expose fake news for what it is. But research has shown that [civilian
reporting](http://www.firstpost.com/tech/news-analysis/the-fake-news-problem-
in-india-can-get-out-of-hand-if-not-controlled-in-due-time-experts-tell-us-
why-3697929.html) of fake news is often not swift or thorough enough to curb
the problem.

At the moment, the most likely mitigators of fake news online may be the
social media companies themselves. But experts are still undecided on whether
or how companies might change their behaviors — by choice or by regulation —
in order to diminish the problem.

### Facebook's “trending” tweaks

As a major venue for the spread of fake news, Facebook has found itself at the
center of this debate. After the 2016 US election, [critics
charged](http://www.npr.org/sections/alltechconsidered/2016/11/11/501743684/zuckerberg-
denies-fake-news-on-facebook-had-impact-on-the-election) that the prevalence
of false stories smearing Hillary Clinton, spread mostly on Facebook, may have
shaped the outcome of the US election. These allegations triggered an ongoing
debate about how Facebook might moderate misinformation on their network,
along with multiple [technical tweaks](https://thewire.in/103045/facebook-
curb-fake-news-new-formula/) by Facebook, in an attempt to make its network
less friendly to fake news distributors.

Most recently, [Facebook updated](https://thewire.in/103045/facebook-curb-
fake-news-new-formula/) its “Trending” feature formula. Unlike in the past,
when the posts with maximum engagement appeared in the “Trending” section, now
only those posts that have been shared by other “reputable sources” will
appear in the Trending section. Users are also invited to contribute to the
system by reporting false news stories directly to the company.

But Facebook CEO [Mark Zuckerberg says](http://www.businessinsider.in/Mark-
Zuckerberg-We-will-rid-site-of-fake-news-but-Identifying-the-truth-is-
complicated/articleshow/55404048.cms) it is difficult to rely on feedback from
users, who may flag potentially correct content as wrong, for vested reasons.
In fact, [recent research](http://www.npr.org/sections/thetwo-
way/2016/11/23/503129818/study-finds-students-have-dismaying-inability-to-
tell-fake-news-from-real) seems to indicate that most people fail to
distinguish between real and fake online content. This, along with the fact
that most of the news that we receive on social media sites are from those in
our close circles (and therefore people we generally trust), makes social
media an ideal platform for propagating fake news.

The only thing that is certain is that there are major pitfalls for any entity
— whether a company, a government, or an individual — that aims to separate
out the real from the fake.

### Thanks to encryption, WhatsApp can't moderate messages

While misinformation continues to circulate on standard social media
platforms, all of the above examples from India reportedly went [viral on
WhatsApp](http://www.indiaspend.com/cover-story/2016-top-10-fake-news-
forwards-that-we-almost-believed-59828). As the internet-based messaging app
has become a key platform for disseminating news and information, for groups
of friends and media houses alike, it has also increasingly served as a
mechanism for distributing fake news.

But the picture becomes more complex when it comes to news and information
spread through WhatsApp.

WhatsApp (which is owned by Facebook) is the [leading messaging
app](https://www.statista.com/statistics/258749/most-popular-global-mobile-
messenger-apps/) for mobile users outside of the US. It is often easier to
access via mobile phone than Facebook or other platforms that carry a higher
volume of content and code.

But in contrast to the technology that supports Facebook, which allows the
company can see and analyze what users post, WhatsApp operators have no way of
seeing the content of users’ messages.

This is because WhatsApp uses end-to-end encryption, where only the sender (on
one end) and receiver (on the other end) can read each other's messages. This
design feature has been a boon for users — including journalists and human
rights advocates — who wish to keep their communications private from
government surveillance.

But when it comes to the proliferation of misinformation, this presents a
significant hurdle. In a recent [interview with the Economic
Times](http://economictimes.indiatimes.com/tech/software/looking-for-ways-to-
minimise-fake-news-on-platform-whatsapp/articleshow/60160111.cms), WhatsApp
software engineer Alan Kao explained that WhatsApp's underlying encryption
makes it difficult to tackle the challenge of fake news, as WhatsApp operators
have no way of seeing what kind of information is being spread on their
networks, unless it is reported to them directly by users.

Like other Facebook-owned products, WhatsApp has a
[policy](https://www.whatsapp.com/legal/#terms-of-service) on acceptable use
which prohibits the use of the app, among other things, to publish
“falsehoods, misrepresentations, or misleading statements.” But this seems
more like a suggestion than a hard and fast rule. The app doesn't offer a
user-friendly way to report violating content, apart from its “Report Spam”
option. In its [FAQ on reporting
“issues”](https://faq.whatsapp.com/en/android/21197244/?category=5245250)
(i.e. problems) to WhatsApp, the company writes:

> We encourage you to report problematic content to us. Please keep in mind
> that to help ensure the safety, confidentiality and security of your
> messages, we generally do not have the contents of messages available to us,
> which limits our ability to verify the report and take action.
>
> When needed, you can take a screenshot of the content and share it, along
> with any available contact info, with appropriate law enforcement
> authorities.

While it is easy to see why the company would encourage users to report
violating behavior to law enforcement, this might not render the best outcome
in a country like India (alongside many others.) Indeed, there have been
[several cases of arrests](http://www.hindustantimes.com/india-news/arrested-
over-a-facebook-status-7-times-people-landed-in-jail-for-posts-against-
politicians/story-ON1jukoStfV6T8aYcJEVGJ.html) of people who have criticized
politicians on WhatsApp. And in April 2017, an [Indian court
ruled](http://economictimes.indiatimes.com/news/politics-and-nation/offensive-
whatsapp-posts-can-now-land-group-administrator-in-
jail/articleshow/58281149.cms) that a WhatsApp group administrator could even
be sentenced to jail time for “offensive” posts.

No matter what, it seems there is always the risk of the powers-that-be taking
undue advantage of their influence over internet activity.

